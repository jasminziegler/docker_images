version: '3.9'
services:
  pdatascience:
    image: pdsc_jpylab_gpu_run:latest
    container_name: pdsc_jpylab_gpu_run
    # restart: unless-stopped
    # https://docs.docker.com/compose/gpu-support/
    deploy:
      resources:
        limits:
          cpus: "0.45"
          memory: 100g
        reservations:
          memory: 12g
          # devices:
          # - driver: nvidia
          #   device_ids: ["0", "1"]
          #   capabilities: ["gpu", "utility"]
    environment:
      - NVIDIA_VISIBLE_DEVICES=0,1
    runtime: nvidia # legacy
    ports:
      - "127.0.0.1:6006-6016:6006-6016" # tensorboard
      - "127.0.0.1:8888:8888" # jupyterlab
    volumes:
      - ./development:/home/user/development:rw
      - ./data:/home/user/data:rw
    shm_size: 4gb # this is very important for pytorch; default value is 64MB
    tty: true

# vgl. https://github.com/docker/compose/issues/6691

# docker run --gpus=all \
#   -v $pwd/development:/home/user/development \
#   -v $pwd/data:/home/user/data \
#   -p 127.0.0.1:6006:6006 \
#   -p 127.0.0.1:8888:8888 \
#   --shm-size=2gb \
#   -it \
#   pdsc_jpylab_gpu:latest
